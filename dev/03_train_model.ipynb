{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TransferLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB6, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers, metrics, layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate the number of menus you want the model to classify\n",
    "num_class = 89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the baseline model: EfficientNet\n",
    "#Options: EfficientNetB0, EfficientNetB1, ... , EfficientNetB7\n",
    "#The higher the number, the more complex the model is\n",
    "#Top layer is not included since we want to perform transfer learning\n",
    "\n",
    "#B6 is used in this case\n",
    "conv_base = EfficientNetB6(input_shape=(224,224,3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform augmentation on training data to increase variation and avoid overfitting\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "# For validation\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25303 images belonging to 89 classes.\n"
     ]
    }
   ],
   "source": [
    "#Initiate batch_size\n",
    "batch_size = 16\n",
    "\n",
    "#Generate training data:\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    # This is the target directory\n",
    "    \"dev_data/train_\" + str(num_class) + \"classes\",\n",
    "    # All images will be resized to target height and width.\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    # Since we use categorical_crossentropy loss, we need categorical labels\n",
    "    class_mode=\"categorical\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2960 images belonging to 89 classes.\n"
     ]
    }
   ],
   "source": [
    "#Generate validation data:\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    # This is the target directory\n",
    "    \"dev_data/validation_\" + str(num_class) + \"classes\",\n",
    "    # All images will be resized to target height and width.\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    # Since we use categorical_crossentropy loss, we need categorical labels\n",
    "    class_mode=\"categorical\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freezing based model didn't work well in my case so I decided to unfreeze all layers\n",
    "conv_base.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define dropout_rate\n",
    "dropout_rate = 0.5\n",
    "\n",
    "#Create a model\n",
    "model = models.Sequential()\n",
    "#Let's start with the base model you downloaded earlier\n",
    "model.add(conv_base)\n",
    "\n",
    "#add dropout layer\n",
    "if dropout_rate > 0:\n",
    "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out4\"))\n",
    "\n",
    "#Add an activation layer with regularization (L1 norm)\n",
    "model.add(layers.Dense(512, activation=\"relu\", name=\"relu1\", kernel_regularizer='l1'))\n",
    "if dropout_rate > 0:\n",
    "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out1\"))\n",
    "\n",
    "#Add a pooling layer\n",
    "model.add(layers.GlobalMaxPooling2D(name=\"gmp\")) \n",
    "\n",
    "#Add the fully-connected layer\n",
    "model.add(layers.Dense(num_class, activation=\"softmax\", name=\"fc_out\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb6 (Functional)  (None, 7, 7, 2304)        40960143  \n",
      "_________________________________________________________________\n",
      "dropout_out4 (Dropout)       (None, 7, 7, 2304)        0         \n",
      "_________________________________________________________________\n",
      "relu1 (Dense)                (None, 7, 7, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "dropout_out1 (Dropout)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "gmp (GlobalMaxPooling2D)     (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc_out (Dense)               (None, 89)                45657     \n",
      "=================================================================\n",
      "Total params: 42,185,960\n",
      "Trainable params: 41,961,521\n",
      "Non-trainable params: 224,439\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#This will show the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show the whole architecture of the base model\n",
    "#conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define optimizer, loss function, and metric\n",
    "model.compile(optimizer=optimizers.Adam(lr = 0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The following lines can be modified to set a callbacks function:\n",
    "Here we have Earlystopping, Modelcheckpoint, and CSVLogger which allow the training process to stop when the model performance stops improving \n",
    "save the respective weights to the predefined path and take log of every process. In this case, we want to minimize the cost function of the validation dataset.\n",
    "\"\"\"\n",
    "model_path = 'dev_model/' + 'B6_' + str(num_class) + 'classes' + '-{epoch:02d}-{val_loss:.2f}.h5'\n",
    "#naming convention: (name of the process)_(number of classes)-(number of epoch)-(evaluation metrics: val_loss).h5\n",
    "keras_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=2, min_lr=0.000001, verbose=1),\n",
    "    ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose = 1, save_best_only=True, mode='min'),\n",
    "    CSVLogger(\"dev_model/B6-Final_log.csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-340bb845d1a4>:10: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/100\n",
      "1581/1581 [==============================] - ETA: 0s - loss: 82.3344 - categorical_accuracy: 0.1204\n",
      "Epoch 00001: val_loss improved from inf to 6.90537, saving model to dev_model/B6_89classes-01-6.91.h5\n",
      "1581/1581 [==============================] - 1180s 747ms/step - loss: 82.3344 - categorical_accuracy: 0.1204 - val_loss: 6.9054 - val_categorical_accuracy: 0.2642\n",
      "Epoch 2/100\n",
      "1581/1581 [==============================] - ETA: 0s - loss: 5.2812 - categorical_accuracy: 0.3566\n",
      "Epoch 00002: val_loss improved from 6.90537 to 4.70724, saving model to dev_model/B6_89classes-02-4.71.h5\n",
      "1581/1581 [==============================] - 1174s 743ms/step - loss: 5.2812 - categorical_accuracy: 0.3566 - val_loss: 4.7072 - val_categorical_accuracy: 0.4608\n",
      "Epoch 3/100\n",
      "  40/1581 [..............................] - ETA: 17:51 - loss: 4.1728 - categorical_accuracy: 0.4453"
     ]
    }
   ],
   "source": [
    "#Let's fit the model!\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator.classes) // batch_size,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator.classes)// batch_size,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=False,\n",
    "    callbacks=keras_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot the training result\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,10) #\"ไว้มาเปลี่ยนเป็น max loss, min loss\"\n",
    "plt.savefig('dev_model/B6_89classes_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot the accuracy \n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('dev_model/B6_89classes_acc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot the loss \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('dev_model/B6_89classes_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
